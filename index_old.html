<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Mingjian Jiang</title>
  <link rel="stylesheet" href="githubmarkdown.css">
  <style>
    .markdown-body {
      box-sizing: border-box;
      min-width: 200px;
      max-width: 980px;
      margin: 0 auto;
      padding: 45px;
    }

    @media (max-width: 767px) {
      .markdown-body {
        padding: 15px;
      }

      .left {
        width: 100%;
      }

      .right {
        width: 100%;
      }

      .portrait {
        margin-bottom: 1em;
      }

      .column-third {
        float: left;
        width: 100%;
      }
    }

    html {
      width: 100vw;
    }

    body {
      overflow-x: hidden;
    }
  </style>
</head>

<body class="markdown-body">
  <h1>Mingjian Jiang</h1>

  <div class="container">
    <div class="image-column">
        <img class="portrait-circular" src="website_new.JPG" alt="Mingjian Jiang">
    </div>
    <div class="content-column">
        <h2>About me</h2>
        <p>Currently, I am a fourth year undergraduate student in University of Toronto, majored in Computer Science Specialist and Mathematics Major Programs. I am interested in the research area of applying statistical methods for achieving better decision making and fairness.</p>
        <p>I am a fan of soccer and Man United, and like playing soccer in my spare time. I am also into stand-up comedy.</p>
    </div>
  </div>

  <h2>Research</h2>

  <p> I worked on different research projects at University of Toronto: 
    <ul>
      <li> <b> Imitation learning from observations </b> &nbsp;&nbsp;&nbsp;&nbsp; I am working on a project about imitation learning from observations supervised by Prof. Amir-massoud Farahmand. We are aiming to propose a new algorithm to solve the suboptimality and inefficiency in some existing imitation learning algorithms, especially in the context that dynamics of the expert and imitator mismatches. This work is funded by University of Toronto Excellence Awards (UTEA) and Professor Farahmand. </li>
     <li> <b> Model extraction and defense </b> &nbsp;&nbsp;&nbsp;&nbsp; This project demonstrates that transformer in the form of API service are susceptible to a novel class of model stealing attacks that are not easily mitigated. Specifically, we introduce two new and practical attacks on language and vision transformers, and propose two initial defences that can be employed to protect transformer-based encoders from theft, particularly in the domains of natural language and vision. I worked on this project under the supervision of Prof. Nicolas Papernot. </li>

     <li> <b> Generative Model for Mixed Integer Programming instances </b> &nbsp;&nbsp;&nbsp;&nbsp; This project aims to build a generative model to create synthetic datasets for an important class of combonatorial optimization problems â€“ Mixed Integer Programming (MIP) to solve the data scarcity, and learn compact latent representation. We parametrize the distribution family over a structured domain, and an autoregressive flow-based model for generation. I worked on this project under the supervision of Prof. Chris Maddison and Prof. Laurent Charlin. </li> 
     </ul> 

  </p>
  <h2> Selected Awards & Honors </h2>
  <li>
    University of Toronto Excellence Award, 2022
  </li>
  <li>
    University of Toronto Scholar, 2020
  </li>
  <li>
    New College Council In-Course Scholarship, 2020, 2021
  </li>
 <li>
    The Robert Bruce Scholarship And Bursary Fund, 2022
  </li>
 
  <h2>Internship Experience</h2>

  <ul>
    <li>
      Research Internship at Vector Institute(Toronto, Canada) Summer 2021
    </li>
     <li>
      Research Internship at Vector Institute(Toronto, Canada) Winter 2022
    </li>
  </ul>

</body>

</html>

